{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"id":"4qy5x2r3w5a3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1705001637657,"user_tz":300,"elapsed":398,"user":{"displayName":"Will Edwards","userId":"01599603330966295958"}},"outputId":"78246b11-97bb-4d55-9568-473912cf85ca"},"outputs":[{"output_type":"stream","name":"stdout","text":["Just a moment... Enable JavaScript and cookies to continue \n","\n"]}],"source":["import requests\n","from bs4 import BeautifulSoup\n","\n","# Make the HTTP request\n","url = 'https://medium.com/towards-data-science/can-chatgpt-write-better-sql-than-a-data-analyst-f079518efab2'\n","response = requests.get(url)\n","\n","# Parse the HTML content with Beautiful Soup\n","soup = BeautifulSoup(response.content, 'html.parser')\n","\n","# Remove unwanted elements (script, style, comments, etc.)\n","for element in soup(['script', 'style', 'comment']):\n","    element.extract()\n","\n","# Extract the visible text\n","text = soup.get_text(separator=' ')\n","\n","# Print the extracted text\n","print(text)\n","\n"]},{"cell_type":"code","source":["def get_and_parse(url):\n","  response = requests.get(url)\n","\n","# Parse the HTML content with Beautiful Soup\n","  soup = BeautifulSoup(response.content, 'html.parser')\n","\n","# Remove unwanted elements (script, style, comments, etc.)\n","  for element in soup(['script', 'style', 'comment']):\n","      element.extract()\n","\n","# Extract the visible text\n","  text = soup.get_text(separator=' ')\n","  return text\n","\n","print(get_and_parse('https://medium.com/towards-data-science/how-to-build-an-elt-with-python-8f5d9d75a12e'))"],"metadata":{"id":"FFt4JOsI7--0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1704983878166,"user_tz":300,"elapsed":301,"user":{"displayName":"Will Edwards","userId":"01599603330966295958"}},"outputId":"8f7dfcf0-20c4-4657-92f5-01e0e8148f54"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Just a moment... Enable JavaScript and cookies to continue \n","\n"]}]},{"cell_type":"code","source":["pip install requests beautifulsoup4 requests-html\n"],"metadata":{"id":"zCaHPJky63_z","colab":{"base_uri":"https://localhost:8080/","height":984},"executionInfo":{"status":"ok","timestamp":1705001670186,"user_tz":300,"elapsed":13669,"user":{"displayName":"Will Edwards","userId":"01599603330966295958"}},"outputId":"321afe69-fc5f-4df6-befb-c6fa9c92e579"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.31.0)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (4.11.2)\n","Collecting requests-html\n","  Downloading requests_html-0.10.0-py3-none-any.whl (13 kB)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2023.11.17)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4) (2.5)\n","Collecting pyquery (from requests-html)\n","  Downloading pyquery-2.0.0-py3-none-any.whl (22 kB)\n","Collecting fake-useragent (from requests-html)\n","  Downloading fake_useragent-1.4.0-py3-none-any.whl (15 kB)\n","Collecting parse (from requests-html)\n","  Downloading parse-1.20.0-py2.py3-none-any.whl (19 kB)\n","Collecting bs4 (from requests-html)\n","  Downloading bs4-0.0.1.tar.gz (1.1 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting w3lib (from requests-html)\n","  Downloading w3lib-2.1.2-py3-none-any.whl (21 kB)\n","Collecting pyppeteer>=0.0.14 (from requests-html)\n","  Downloading pyppeteer-1.0.2-py3-none-any.whl (83 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.4/83.4 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: appdirs<2.0.0,>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from pyppeteer>=0.0.14->requests-html) (1.4.4)\n","Requirement already satisfied: importlib-metadata>=1.4 in /usr/local/lib/python3.10/dist-packages (from pyppeteer>=0.0.14->requests-html) (7.0.1)\n","Collecting pyee<9.0.0,>=8.1.0 (from pyppeteer>=0.0.14->requests-html)\n","  Downloading pyee-8.2.2-py2.py3-none-any.whl (12 kB)\n","Requirement already satisfied: tqdm<5.0.0,>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from pyppeteer>=0.0.14->requests-html) (4.66.1)\n","Collecting urllib3<3,>=1.21.1 (from requests)\n","  Downloading urllib3-1.26.18-py2.py3-none-any.whl (143 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.8/143.8 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting websockets<11.0,>=10.0 (from pyppeteer>=0.0.14->requests-html)\n","  Downloading websockets-10.4-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (106 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.8/106.8 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: lxml>=2.1 in /usr/local/lib/python3.10/dist-packages (from pyquery->requests-html) (4.9.4)\n","Collecting cssselect>=1.2.0 (from pyquery->requests-html)\n","  Downloading cssselect-1.2.0-py2.py3-none-any.whl (18 kB)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=1.4->pyppeteer>=0.0.14->requests-html) (3.17.0)\n","Building wheels for collected packages: bs4\n","  Building wheel for bs4 (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for bs4: filename=bs4-0.0.1-py3-none-any.whl size=1256 sha256=55bf6bb5b912c5457e7c4c0586258f2e872d49a5152f89d57ac4d87e3906a86a\n","  Stored in directory: /root/.cache/pip/wheels/25/42/45/b773edc52acb16cd2db4cf1a0b47117e2f69bb4eb300ed0e70\n","Successfully built bs4\n","Installing collected packages: pyee, parse, fake-useragent, websockets, w3lib, urllib3, cssselect, pyquery, pyppeteer, bs4, requests-html\n","  Attempting uninstall: urllib3\n","    Found existing installation: urllib3 2.0.7\n","    Uninstalling urllib3-2.0.7:\n","      Successfully uninstalled urllib3-2.0.7\n","Successfully installed bs4-0.0.1 cssselect-1.2.0 fake-useragent-1.4.0 parse-1.20.0 pyee-8.2.2 pyppeteer-1.0.2 pyquery-2.0.0 requests-html-0.10.0 urllib3-1.26.18 w3lib-2.1.2 websockets-10.4\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["urllib3"]}}},"metadata":{}}]},{"cell_type":"code","source":["import pandas as pd\n","from urllib.parse import urlparse\n","import numpy as np\n","import nltk.data\n","from requests_html import HTMLSession"],"metadata":{"id":"mIpPEu8v8AA9","executionInfo":{"status":"ok","timestamp":1705001704365,"user_tz":300,"elapsed":3513,"user":{"displayName":"Will Edwards","userId":"01599603330966295958"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["def parse_elements(url,element):\n","    session = HTMLSession()\n","    r = session.get(url)\n","    elements = r.html.find(element)\n","    return elements"],"metadata":{"id":"d00LzkUZ8BFK","executionInfo":{"status":"ok","timestamp":1705001837774,"user_tz":300,"elapsed":6,"user":{"displayName":"Will Edwards","userId":"01599603330966295958"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["url = 'https://medium.com/towards-data-science/ai-scaling-why-keeping-up-is-essential-and-how-to-do-it-56be3c2e1e5'"],"metadata":{"id":"mR5_9sTA8GSt","executionInfo":{"status":"ok","timestamp":1705001854953,"user_tz":300,"elapsed":155,"user":{"displayName":"Will Edwards","userId":"01599603330966295958"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["#url = 'https://www.amazon.ca/s?k=amazon+iphone&hvadid=208383377667&hvdev=c&hvlocphy=9061009&hvnetw=g&hvqmt=e&hvrand=15052642443271265009&hvtargid=kwd-320030418394&hydadcr=23342_10093192&tag=googcana-20&ref=pd_sl_9sb8n719tv_e'"],"metadata":{"id":"k3JvPY310e1z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["paragraphs = parse_elements(url, 'p')\n","links = parse_elements(url, 'a')"],"metadata":{"id":"xYmg7zid8HDx","executionInfo":{"status":"ok","timestamp":1705001930165,"user_tz":300,"elapsed":2471,"user":{"displayName":"Will Edwards","userId":"01599603330966295958"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["(paragraphs[20]).attrs"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_kVY_AJjfBcy","executionInfo":{"status":"ok","timestamp":1705002081688,"user_tz":300,"elapsed":198,"user":{"displayName":"Will Edwards","userId":"01599603330966295958"}},"outputId":"2a0af610-d313-4dce-a588-6f3aa7beda9a"},"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'id': '3147',\n"," 'class': ('pw-post-body-paragraph',\n","  'ok',\n","  'ol',\n","  'gr',\n","  'om',\n","  'b',\n","  'hv',\n","  'on',\n","  'oo',\n","  'op',\n","  'hy',\n","  'oq',\n","  'or',\n","  'os',\n","  'ot',\n","  'ou',\n","  'ov',\n","  'ow',\n","  'ox',\n","  'oy',\n","  'oz',\n","  'pa',\n","  'pb',\n","  'pc',\n","  'pd',\n","  'pe',\n","  'pf',\n","  'gk',\n","  'bj')}"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["(links[10]).attrs['href']"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"ZkMo1bHXsN-o","executionInfo":{"status":"ok","timestamp":1705002207442,"user_tz":300,"elapsed":227,"user":{"displayName":"Will Edwards","userId":"01599603330966295958"}},"outputId":"c6294be8-57fa-48cf-8d1e-37dad26ff75f"},"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'https://medium.com/@JeremieHarris?source=post_page-----56be3c2e1e5--------------------------------'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":22}]},{"cell_type":"code","source":[],"metadata":{"id":"EY4NhLhTDPy7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["set1 = {'a','a','b',3,7}\n","set1\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"O1s_dIm13STv","executionInfo":{"status":"ok","timestamp":1705002229071,"user_tz":300,"elapsed":179,"user":{"displayName":"Will Edwards","userId":"01599603330966295958"}},"outputId":"ccdb1f21-d952-4b36-a376-dc0e755076ef"},"execution_count":23,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{3, 7, 'a', 'b'}"]},"metadata":{},"execution_count":23}]},{"cell_type":"code","source":["len(links)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kEfmtYLWniU1","executionInfo":{"status":"ok","timestamp":1701287185003,"user_tz":300,"elapsed":323,"user":{"displayName":"Will Edwards","userId":"01599603330966295958"}},"outputId":"d9982def-0c9c-4c6b-960d-fb8e659f297a"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["138"]},"metadata":{},"execution_count":83}]},{"cell_type":"code","source":["links_set = set()\n","for link in links:\n","  links_set.add(link.attrs['href'])\n","len(links_set)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8Aq6Y0Lc1jS4","executionInfo":{"status":"ok","timestamp":1705002273562,"user_tz":300,"elapsed":184,"user":{"displayName":"Will Edwards","userId":"01599603330966295958"}},"outputId":"df06cd68-c273-48a1-b368-707401126c1a"},"execution_count":24,"outputs":[{"output_type":"execute_result","data":{"text/plain":["34"]},"metadata":{},"execution_count":24}]},{"cell_type":"code","source":["(paragraphs[0]).text"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"1w_5vm3Dlr-b","executionInfo":{"status":"ok","timestamp":1705002295766,"user_tz":300,"elapsed":165,"user":{"displayName":"Will Edwards","userId":"01599603330966295958"}},"outputId":"6394704a-8cf0-43e5-86bb-103c1d0c12bf"},"execution_count":25,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'Sign up'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":25}]},{"cell_type":"code","source":["for p in paragraphs:\n","  print(p.text)"],"metadata":{"id":"X3pxfsXW0u-c","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1705002306405,"user_tz":300,"elapsed":152,"user":{"displayName":"Will Edwards","userId":"01599603330966295958"}},"outputId":"9bca41ac-db85-4162-d09e-b154171c4019"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["Sign up\n","Sign in\n","Sign up\n","Sign in\n","Jeremie Harris\n","Follow\n","Towards Data Science\n","--\n","1\n","Listen\n","Share\n","GPT-3 came out in early 2020, and shocked the world.\n","For the first time, we had an AI system that could write text so humanlike that readers consistently couldn’t tell that it was AI-generated. But more than that, GPT-3 could also translate between languages, write code, answer questions, and much more.\n","And it did all thing thanks simply to its scale. GPT-3 was a much larger model, featuring more parameters than any transformer ever developed before. And it was trained using an appropriately massive amount of processing power, and a huge dataset which amounted to essentially all the text on the internet at the time.\n","The idea that simply by scaling a simple transformer architecture — an architecture which had by then already been around for three years! — we could achieve a significant level of general intelligence and human-like text generation capability came as a shock to just about everyone. But it had enormous consequences: by building GPT-3 and announcing it to the world in such a public fashion, OpenAI drew the world’s attention to the AI scaling phenomenon.\n","Since then, dozens of other companies have put forward their own superscaled AI models with increasingly astonishing capabilities. Google AI, DeepMind, Mircosoft, NVIDIA, Cohere, AI21Labs, and many more Western groups have entered the fray. And Chinese labs at Huawei, Inspur, the Beijing Academy of AI, and Tsinghua University have been close to the frontier of AI scaling, too — despite export controls that make it harder for them to get their hands on the processing power that’s so critical to scaling AI.\n","The one-fringe AI scaling strategy that OpenAI first doubled down on in 2020 is now becoming the de facto consensus approach by world-leading labs everywhere. And although the specific recipe OpenAI proposed with GPT-3 has since been shown to be sub-optimal (as DeepMind’s Chinchilla showed), the fact remains: we now have a reliable way of pumping in more scale — more data, more processing power, and larger models — and getting more intelligence and more capabilities out of our AI systems.\n","And there’s no end in sight: as the dizzying pace of AI progress in the last few months has shown, scaling just seems to keep paying dividends. Google’s Minerva model can solve undergraduate-level math problems. DeepMind’s Flamingo — and many other scaled multi-modal models since — are showing that scaling makes it possible for AI to process and output text, image, video, and other data shockingly well. Once the stuff of scifi fantasy, text-to-image, text-to-video, and really, text-to-anything models are now mundane everyday realities.\n","Missing out on just one of these developments can lead to critical blind spots. Here are some that we discuss in this first episode of the Gladstone AI podcast:\n","Keeping up with the current state of the art in AI is becoming a must — not just for data scientists, data analysts, MLEs, and so on, but also for entirely nontechnical people who, like the rest of us, are directly impacted by the state of cutting-edge AI in a way we’ve never been before.\n","This immediately implies that one of the most valuable skills of the coming AI era will be the ability to translate new technical developments into nontechnical language. As progress in AI accelerates, the gap between actual AI and perceived AI capabilities will get larger, and an organization’s ability to compete will become bottlenecked by the rate at which it can recognize and leverage the latest AI tooling. People who can live at the boundary between the technical world of AI scaling and the nontechnical world of business strategy are going to become some of the most prized assets in every organization.\n","In future episodes, we’ll look at these big “what now” questions in more detail, in the context of more recent advances in AI.\n","--\n","--\n","1\n","Towards Data Science\n","Co-founder of Gladstone AI 🤖 an AI safety company. Author of Quantum Mechanics Made Me Do It (preorder: shorturl.at/jtMN0).\n","Help\n","Status\n","About\n","Careers\n","Blog\n","Privacy\n","Terms\n","Text to speech\n","Teams\n"]}]},{"cell_type":"code","source":["for a in links:\n","  print(a.text)"],"metadata":{"id":"40jkw3Zs1pt9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1705002350829,"user_tz":300,"elapsed":162,"user":{"displayName":"Will Edwards","userId":"01599603330966295958"}},"outputId":"43a2bd34-b5f2-4b6c-d370-af86bf80a18f"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["Open in app\n","Sign up\n","Sign in\n","\n","Write\n","\n","Sign up\n","Sign in\n","\n","\n","Jeremie Harris\n","Follow\n","Towards Data Science\n","\n","\n","already rely\n","thispersondoesnotexist.com\n","global catastrophic risk\n","Spotify\n","Artificial Intelligence\n","Gpt 3\n","National Security\n","Gladstone Ai\n","Data Science\n","\n","\n","\n","\n","\n","Follow\n","\n","Written by Jeremie Harris\n","122K Followers\n","Towards Data Science\n","shorturl.at/jtMN0\n","Follow\n","\n","Help\n","Status\n","About\n","Careers\n","Blog\n","Privacy\n","Terms\n","Text to speech\n","Teams\n"]}]},{"cell_type":"code","source":["points = parse_elements(url, 'li')"],"metadata":{"id":"NsjbZ06I3NbQ","executionInfo":{"status":"ok","timestamp":1705002414279,"user_tz":300,"elapsed":1574,"user":{"displayName":"Will Edwards","userId":"01599603330966295958"}}},"execution_count":28,"outputs":[]},{"cell_type":"code","source":["for point in points:\n","  print(point.text)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"szYBVhJO3V7u","executionInfo":{"status":"ok","timestamp":1705002420341,"user_tz":300,"elapsed":171,"user":{"displayName":"Will Edwards","userId":"01599603330966295958"}},"outputId":"19720620-941c-49f5-cb07-fff95d9bd4e4"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["If you didn’t know text-to-image was now possible, you’d be more likely to buy into social media influence operations, some of which already rely on AI-generated images to support false narratives. (As a simple and already wildly out-of-date example, Russian operatives are known to have used thispersondoesnotexist.com to generate fake Twitter profile pictures for their interference campaigns.)\n","If you weren’t aware of the state of language modelling today, you might miss on an opportunity to deploy reliable and effective, fully automated customer service chatbots.\n","If you weren’t tracking AI-powered code generation, you might not be aware that we’re about to enter a new era of AI-augmented malware.\n","If you weren’t tracking breakthroughs in general-purpose AI, you might not realize that we’re plausibly approaching an era of broadly human-level intelligence, in which AI accidents become a source of global catastrophic risk.\n","0:00 Introduction\n","1:38 GPT-3 and AI scaling\n","7:06 Explosion of new applications\n","9:40 Why autocomplete led to an AI revolution\n","13:03 The strategic implications of AI scaling\n","17:27 Risks: AI-powered election interference, phishing, and bots\n","27:40 Risks: AI accidents in GPT-3\n","31:30 Risks: Global catastrophic risk from AI accidents\n","35:50 Wrap-up\n"]}]},{"cell_type":"code","source":["#let's revisit this function we saw the other day\n","def sentiment_detection(sentence):\n","    positive_words = ('happy', 'sunny', 'positive', 'triumphant', 'optimistic', 'wonderful')\n","    negative_words = ('sad', 'terrible', 'frightening', 'rainy', 'scary', 'shocked')\n","\n","    positive = any(sentence.count(i) > 0 for i in positive_words)\n","    negative = any(sentence.count(i) > 0 for i in negative_words)\n","\n","    if positive == negative == False:\n","        return \"neutral\"\n","    elif positive != negative:\n","        return \"positive\" if positive else \"negative\"\n","    else:\n","        return \"mixed\""],"metadata":{"id":"bYNYeberVUUV","executionInfo":{"status":"ok","timestamp":1705002466966,"user_tz":300,"elapsed":158,"user":{"displayName":"Will Edwards","userId":"01599603330966295958"}}},"execution_count":30,"outputs":[]},{"cell_type":"code","source":["#repurpose our sentiment analysis as topic detection\n","#detect are people talking about data science, AI, or data in general?\n","def topic_detection(sentence):\n","    DataScience_words = ('data science', 'regression', 'predict', 'predictive', 'classify', 'Python','Pandas')\n","    AI_words = ('AI', 'machine learning', 'ml', 'ML', 'NLP', 'LLM','deep learning','neural network','generative', 'GPT-3','TensorFlow')\n","    DataWords = ('analysis', 'algorithms','data','data structure','data-structure','big data', 'SQL')\n","    DataScience = any(sentence.count(i) > 0 for i in DataScience_words)\n","    AI = any(sentence.count(i) > 0 for i in AI_words)\n","    data = any(sentence.count(i) > 0 for i in DataWords)\n","    topics = []\n","    if DataScience == True:\n","        topics.append(\"Data Science\")\n","    if AI == True:\n","        topics.append(\"AI\")\n","    if data == True:\n","        topics.append(\"data\")\n","    return topics\n"],"metadata":{"id":"XGLV9IUtWeOd","executionInfo":{"status":"ok","timestamp":1705002549205,"user_tz":300,"elapsed":207,"user":{"displayName":"Will Edwards","userId":"01599603330966295958"}}},"execution_count":31,"outputs":[]},{"cell_type":"code","source":["#requirements: print out a sentiment analysis after every paragraph prints out\n","#print(paragraphs)\n","for p in range(0, len(paragraphs)):\n","    if len(paragraphs[p].text) > 50:\n","      print((paragraphs[p].text))\n","      print(f\"TALKS ABOUT: {topic_detection(paragraphs[p].text)}\")"],"metadata":{"id":"_NJZgGMVRmv3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for p in paragraphs:\n","    if len(p.text) > 50:\n","      print(p.text)\n","      print(f\"TALKS ABOUT: {topic_detection(p.text)}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ik1rGNr4FLXZ","executionInfo":{"status":"ok","timestamp":1705002765607,"user_tz":300,"elapsed":141,"user":{"displayName":"Will Edwards","userId":"01599603330966295958"}},"outputId":"0451d08c-ddcc-42db-c837-11ecb4344657"},"execution_count":36,"outputs":[{"output_type":"stream","name":"stdout","text":["GPT-3 came out in early 2020, and shocked the world.\n","TALKS ABOUT: ['AI']\n","For the first time, we had an AI system that could write text so humanlike that readers consistently couldn’t tell that it was AI-generated. But more than that, GPT-3 could also translate between languages, write code, answer questions, and much more.\n","TALKS ABOUT: ['AI']\n","And it did all thing thanks simply to its scale. GPT-3 was a much larger model, featuring more parameters than any transformer ever developed before. And it was trained using an appropriately massive amount of processing power, and a huge dataset which amounted to essentially all the text on the internet at the time.\n","TALKS ABOUT: ['AI', 'data']\n","The idea that simply by scaling a simple transformer architecture — an architecture which had by then already been around for three years! — we could achieve a significant level of general intelligence and human-like text generation capability came as a shock to just about everyone. But it had enormous consequences: by building GPT-3 and announcing it to the world in such a public fashion, OpenAI drew the world’s attention to the AI scaling phenomenon.\n","TALKS ABOUT: ['AI']\n","Since then, dozens of other companies have put forward their own superscaled AI models with increasingly astonishing capabilities. Google AI, DeepMind, Mircosoft, NVIDIA, Cohere, AI21Labs, and many more Western groups have entered the fray. And Chinese labs at Huawei, Inspur, the Beijing Academy of AI, and Tsinghua University have been close to the frontier of AI scaling, too — despite export controls that make it harder for them to get their hands on the processing power that’s so critical to scaling AI.\n","TALKS ABOUT: ['AI']\n","The one-fringe AI scaling strategy that OpenAI first doubled down on in 2020 is now becoming the de facto consensus approach by world-leading labs everywhere. And although the specific recipe OpenAI proposed with GPT-3 has since been shown to be sub-optimal (as DeepMind’s Chinchilla showed), the fact remains: we now have a reliable way of pumping in more scale — more data, more processing power, and larger models — and getting more intelligence and more capabilities out of our AI systems.\n","TALKS ABOUT: ['AI', 'data']\n","And there’s no end in sight: as the dizzying pace of AI progress in the last few months has shown, scaling just seems to keep paying dividends. Google’s Minerva model can solve undergraduate-level math problems. DeepMind’s Flamingo — and many other scaled multi-modal models since — are showing that scaling makes it possible for AI to process and output text, image, video, and other data shockingly well. Once the stuff of scifi fantasy, text-to-image, text-to-video, and really, text-to-anything models are now mundane everyday realities.\n","TALKS ABOUT: ['AI', 'data']\n","Missing out on just one of these developments can lead to critical blind spots. Here are some that we discuss in this first episode of the Gladstone AI podcast:\n","TALKS ABOUT: ['AI']\n","Keeping up with the current state of the art in AI is becoming a must — not just for data scientists, data analysts, MLEs, and so on, but also for entirely nontechnical people who, like the rest of us, are directly impacted by the state of cutting-edge AI in a way we’ve never been before.\n","TALKS ABOUT: ['AI', 'data']\n","This immediately implies that one of the most valuable skills of the coming AI era will be the ability to translate new technical developments into nontechnical language. As progress in AI accelerates, the gap between actual AI and perceived AI capabilities will get larger, and an organization’s ability to compete will become bottlenecked by the rate at which it can recognize and leverage the latest AI tooling. People who can live at the boundary between the technical world of AI scaling and the nontechnical world of business strategy are going to become some of the most prized assets in every organization.\n","TALKS ABOUT: ['AI']\n","In future episodes, we’ll look at these big “what now” questions in more detail, in the context of more recent advances in AI.\n","TALKS ABOUT: ['AI']\n","Co-founder of Gladstone AI 🤖 an AI safety company. Author of Quantum Mechanics Made Me Do It (preorder: shorturl.at/jtMN0).\n","TALKS ABOUT: ['AI']\n"]}]},{"cell_type":"code","source":["for p in range(0, len(points)):\n","    #if len(points[p].text) > 50:\n","    print((points[p].text))\n","    print(f\"TALKS ABOUT: {topic_detection(points[p].text)}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NVATkwM06UPc","executionInfo":{"status":"ok","timestamp":1705002823607,"user_tz":300,"elapsed":211,"user":{"displayName":"Will Edwards","userId":"01599603330966295958"}},"outputId":"a3d3202c-d84f-430e-e655-9270c464a5ce"},"execution_count":37,"outputs":[{"output_type":"stream","name":"stdout","text":["If you didn’t know text-to-image was now possible, you’d be more likely to buy into social media influence operations, some of which already rely on AI-generated images to support false narratives. (As a simple and already wildly out-of-date example, Russian operatives are known to have used thispersondoesnotexist.com to generate fake Twitter profile pictures for their interference campaigns.)\n","TALKS ABOUT: ['AI']\n","If you weren’t aware of the state of language modelling today, you might miss on an opportunity to deploy reliable and effective, fully automated customer service chatbots.\n","TALKS ABOUT: []\n","If you weren’t tracking AI-powered code generation, you might not be aware that we’re about to enter a new era of AI-augmented malware.\n","TALKS ABOUT: ['AI']\n","If you weren’t tracking breakthroughs in general-purpose AI, you might not realize that we’re plausibly approaching an era of broadly human-level intelligence, in which AI accidents become a source of global catastrophic risk.\n","TALKS ABOUT: ['AI']\n","0:00 Introduction\n","TALKS ABOUT: []\n","1:38 GPT-3 and AI scaling\n","TALKS ABOUT: ['AI']\n","7:06 Explosion of new applications\n","TALKS ABOUT: []\n","9:40 Why autocomplete led to an AI revolution\n","TALKS ABOUT: ['AI']\n","13:03 The strategic implications of AI scaling\n","TALKS ABOUT: ['AI']\n","17:27 Risks: AI-powered election interference, phishing, and bots\n","TALKS ABOUT: ['AI']\n","27:40 Risks: AI accidents in GPT-3\n","TALKS ABOUT: ['AI']\n","31:30 Risks: Global catastrophic risk from AI accidents\n","TALKS ABOUT: ['AI']\n","35:50 Wrap-up\n","TALKS ABOUT: []\n"]}]},{"cell_type":"code","source":["for p in range(0, len(points)):\n","    #if len(paragraphs[p].text) > 50:\n","    print((points[p].text))\n","    print(f\"TALKS ABOUT: {topic_detection(points[p].text)}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"enVaHlJx6YsG","executionInfo":{"status":"ok","timestamp":1705002838306,"user_tz":300,"elapsed":223,"user":{"displayName":"Will Edwards","userId":"01599603330966295958"}},"outputId":"3428d0b1-7f4d-4b61-c7da-ee5d4cc7e7f4"},"execution_count":38,"outputs":[{"output_type":"stream","name":"stdout","text":["If you didn’t know text-to-image was now possible, you’d be more likely to buy into social media influence operations, some of which already rely on AI-generated images to support false narratives. (As a simple and already wildly out-of-date example, Russian operatives are known to have used thispersondoesnotexist.com to generate fake Twitter profile pictures for their interference campaigns.)\n","TALKS ABOUT: ['AI']\n","If you weren’t aware of the state of language modelling today, you might miss on an opportunity to deploy reliable and effective, fully automated customer service chatbots.\n","TALKS ABOUT: []\n","If you weren’t tracking AI-powered code generation, you might not be aware that we’re about to enter a new era of AI-augmented malware.\n","TALKS ABOUT: ['AI']\n","If you weren’t tracking breakthroughs in general-purpose AI, you might not realize that we’re plausibly approaching an era of broadly human-level intelligence, in which AI accidents become a source of global catastrophic risk.\n","TALKS ABOUT: ['AI']\n","0:00 Introduction\n","TALKS ABOUT: []\n","1:38 GPT-3 and AI scaling\n","TALKS ABOUT: ['AI']\n","7:06 Explosion of new applications\n","TALKS ABOUT: []\n","9:40 Why autocomplete led to an AI revolution\n","TALKS ABOUT: ['AI']\n","13:03 The strategic implications of AI scaling\n","TALKS ABOUT: ['AI']\n","17:27 Risks: AI-powered election interference, phishing, and bots\n","TALKS ABOUT: ['AI']\n","27:40 Risks: AI accidents in GPT-3\n","TALKS ABOUT: ['AI']\n","31:30 Risks: Global catastrophic risk from AI accidents\n","TALKS ABOUT: ['AI']\n","35:50 Wrap-up\n","TALKS ABOUT: []\n"]}]},{"cell_type":"code","source":["reddit_url = 'https://www.reddit.com/r/askmath/'\n","hyperlinks = parse_elements(reddit_url, 'a')"],"metadata":{"id":"S0apadGL8T1r","executionInfo":{"status":"ok","timestamp":1705003057121,"user_tz":300,"elapsed":326,"user":{"displayName":"Will Edwards","userId":"01599603330966295958"}}},"execution_count":39,"outputs":[]},{"cell_type":"code","source":["hyperlinks"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VEU_wuucLIIf","executionInfo":{"status":"ok","timestamp":1705003059859,"user_tz":300,"elapsed":158,"user":{"displayName":"Will Edwards","userId":"01599603330966295958"}},"outputId":"b3bcd0e0-11e0-4666-888c-cb2b69ad0c8a"},"execution_count":40,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[<Element 'a' href='https://www.reddit.com/login/'>,\n"," <Element 'a' href='https://www.reddit.com/wiki/api/'>,\n"," <Element 'a' href='https://www.reddit.com/wiki/api/'>,\n"," <Element 'a' href='https://support.reddithelp.com/hc/en-us/requests/new?ticket_form_id=21879292693140'>]"]},"metadata":{},"execution_count":40}]},{"cell_type":"code","source":["exception_list = []"],"metadata":{"id":"WYMyZspDuICf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#for context, exceptions and exception handling a simple example\n","def return_first(x):\n","  try:\n","    return x[0]\n","  except Exception:\n","    return \"sorry can't do that on that input\"\n","return_first({3,6,9,0})"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"d8Yh3khc_QEO","executionInfo":{"status":"ok","timestamp":1705003275696,"user_tz":300,"elapsed":187,"user":{"displayName":"Will Edwards","userId":"01599603330966295958"}},"outputId":"a98aebf9-f360-4f98-9ee3-623ede61b81e"},"execution_count":46,"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"sorry can't do that on that input\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":46}]},{"cell_type":"code","source":["return_first((1,3,7,8))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RoJIefDPIGon","executionInfo":{"status":"ok","timestamp":1704986842404,"user_tz":300,"elapsed":863,"user":{"displayName":"Will Edwards","userId":"01599603330966295958"}},"outputId":"c20f17cc-d4cd-42df-9069-a02ea434b31d"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1"]},"metadata":{},"execution_count":48}]},{"cell_type":"code","source":["for hyperlink in hyperlinks:\n","    #print(hyperlink.html)\n","    #print((hyperlink).absolute_links)\n","    try:\n","      print((hyperlink).absolute_links.pop())\n","    except Exception:\n","      exception_list.append((hyperlink))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qkNzHJkEpira","executionInfo":{"status":"ok","timestamp":1705003351993,"user_tz":300,"elapsed":144,"user":{"displayName":"Will Edwards","userId":"01599603330966295958"}},"outputId":"cf316d42-7848-4f7a-f750-1fa9333ea1bf"},"execution_count":49,"outputs":[{"output_type":"stream","name":"stdout","text":["https://www.reddit.com/login/\n","https://www.reddit.com/wiki/api/\n","https://www.reddit.com/wiki/api/\n","https://support.reddithelp.com/hc/en-us/requests/new?ticket_form_id=21879292693140\n"]}]},{"cell_type":"code","source":["exception_list"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rxtxASWECm43","executionInfo":{"status":"ok","timestamp":1704987295864,"user_tz":300,"elapsed":6,"user":{"displayName":"Will Edwards","userId":"01599603330966295958"}},"outputId":"004b5a84-e4ea-4132-eea5-44d566149fd3"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[]"]},"metadata":{},"execution_count":57}]},{"cell_type":"code","source":["# Print the string versions of the hyperlinks\n","for hyperlink in hyperlinks:\n","      try:\n","        if ((hyperlink.absolute_links).pop()).count('/r/askmath/comments') > 0:\n","          print((hyperlink).absolute_links.pop())\n","      except Exception:\n","        exception_list.append((hyperlink))\n","\n","def get_threads(webdata,name):\n","  for hyperlink in webdata:\n","    try:\n","      if ((hyperlink.absolute_links).pop()).count(f'/r/{name}/comments') > 0:\n","        print((hyperlink.absolute_links).pop())\n","    except Exception:\n","      pass"],"metadata":{"id":"6CLRABsC8T4g","executionInfo":{"status":"ok","timestamp":1705003656149,"user_tz":300,"elapsed":133,"user":{"displayName":"Will Edwards","userId":"01599603330966295958"}}},"execution_count":50,"outputs":[]},{"cell_type":"code","source":["hyperlinks2 = parse_elements(\"https://www.reddit.com/r/learnprogramming/\", 'a')\n","get_threads(hyperlinks2,\"learnprogramming\")"],"metadata":{"id":"lxeZR5dRE9LV","executionInfo":{"status":"ok","timestamp":1705004512019,"user_tz":300,"elapsed":336,"user":{"displayName":"Will Edwards","userId":"01599603330966295958"}}},"execution_count":51,"outputs":[]},{"cell_type":"code","source":["#OR try this implementation that just gets the HREF's from the elements that it finds and gets them in string form.\n","def parse_href(url, element):\n","    session = HTMLSession()\n","    r = session.get(url)\n","    elements = r.html.find(element)\n","    links = [element.attrs['href'] for element in elements if 'href' in element.attrs]\n","    return links\n"],"metadata":{"id":"7Lrnc4Oi8T7c","executionInfo":{"status":"ok","timestamp":1705004597323,"user_tz":300,"elapsed":141,"user":{"displayName":"Will Edwards","userId":"01599603330966295958"}}},"execution_count":52,"outputs":[]},{"cell_type":"code","source":["reddit_url = 'https://www.reddit.com/r/askmath/'\n","hyperlinks = parse_href(reddit_url, 'a')\n","\n","# Print the string versions of the hyperlinks\n","for hyperlink in hyperlinks:\n","    if '/r/askmath/comments' in hyperlink:\n","      print(hyperlink)\n"],"metadata":{"id":"TpNYWDX2DAbd","executionInfo":{"status":"ok","timestamp":1705004603025,"user_tz":300,"elapsed":299,"user":{"displayName":"Will Edwards","userId":"01599603330966295958"}}},"execution_count":53,"outputs":[]},{"cell_type":"markdown","source":["*we may not get here today*\n","There are some interesting things we can do with NLTK when analyzing text data. Such as breaking a paragraph into its constituent sentences."],"metadata":{"id":"QReT75a18UT2"}},{"cell_type":"code","source":["#takes a paragraph as string and breaks it down into sentences\n","def sentence_list(paragraph_string):\n","    tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n","    list_of_sentences = tokenizer.tokenize(paragraph_string)\n","    return list_of_sentences"],"metadata":{"id":"9VytK-2o8HNk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sentences = sentence_list('The objective is to generate a CSV file from a given Pandas DataFrame. For Pandas, we are already aware of the df.to_csv() method. However, to create a CSV from Dask and DataTable, we first need to convert the given Pandas DataFrame to their respective DataFrames and then store them in a CSV. Thus, we’ll also consider the time taken for this DataFrame conversion in this analysis.')"],"metadata":{"id":"PRokY2f5YqDQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sentences = sentence_list('He asked, \"will nltk be updated by wednesday?\" when he realized that punkt had to be installed separately. This is part of a larger issue, where modules within NLTK need to be downloaded separately. Developers are hoping to fork the code-base soon.')"],"metadata":{"id":"M3kgVLZq5Ni7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sentences"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"z_ul3eHaZBYY","executionInfo":{"status":"ok","timestamp":1695068713899,"user_tz":240,"elapsed":453,"user":{"displayName":"Will Edwards","userId":"01599603330966295958"}},"outputId":"1f9b9e5c-3fd4-4d7a-9c99-a1e560c31481"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['The objective is to generate a CSV file from a given Pandas DataFrame.',\n"," 'For Pandas, we are already aware of the df.to_csv() method.',\n"," 'However, to create a CSV from Dask and DataTable, we first need to convert the given Pandas DataFrame to their respective DataFrames and then store them in a CSV.',\n"," 'Thus, we’ll also consider the time taken for this DataFrame conversion in this analysis.']"]},"metadata":{},"execution_count":69}]},{"cell_type":"code","source":["for sentence in sentences:\n","  print(sentence)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AOKANx4F49VG","executionInfo":{"status":"ok","timestamp":1695068844084,"user_tz":240,"elapsed":355,"user":{"displayName":"Will Edwards","userId":"01599603330966295958"}},"outputId":"ba257fd8-0069-4698-a6fc-7eb856aa6a5d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["He asked, \"will nltk be updated by wednesday?\"\n","when he realized that punkt had to be installed separately.\n","This is part of a larger issue, where modules within NLTK need to be downloaded separately.\n","Developers are hoping to fork the code-base soon.\n"]}]},{"cell_type":"code","source":["nltk.download('punkt')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4kfrkcExY8pJ","executionInfo":{"status":"ok","timestamp":1695068702288,"user_tz":240,"elapsed":498,"user":{"displayName":"Will Edwards","userId":"01599603330966295958"}},"outputId":"8c7f94fb-fa08-4de5-fb86-153f6974cdae"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":67}]},{"cell_type":"markdown","source":["Can we apply a rules based themes/sentiment analysis like we saw yesterday to the data we scrape from the web?\n","Yes."],"metadata":{"id":"TpbDiW6XEplI"}},{"cell_type":"code","source":["pip install tensorflow==2.12."],"metadata":{"id":"i1BnWrKqEohC"},"execution_count":null,"outputs":[]}]}